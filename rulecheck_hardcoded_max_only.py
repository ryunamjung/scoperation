from __future__ import annotations

import io
import re
from datetime import datetime
from typing import Dict, List, Set

import pandas as pd
import streamlit as st


# ============================================================
# âœ… í•˜ë“œì½”ë”© RULES (ê° íŒŒì¼ì˜ case_n ìµœëŒ€ê°’ê³¼ ë™ì¼í•œ í–‰ë§Œ)
# ============================================================
RULES: Dict[str, dict] = {
    # (ì‚¬ìš©ì ì œê³µ RULES ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤)
    # ... ìƒëµí•˜ì§€ ë§ê³  í˜„ì¬ ê°–ê³  ìˆëŠ” RULES ì „ì²´ë¥¼ ì—¬ê¸° ë¶™ì—¬ë„£ìœ¼ì„¸ìš” ...
}

# -----------------------------
# ê³µí†µ: ë³µë¶™ íŒŒì„œ
# -----------------------------
EXPECTED_COLS = [
    "ì„ íƒ", "ì²˜ë°©ì½”ë“œ", "ì²­êµ¬ì½”ë“œ", "ì²˜ë°©ëª…", "í•­ëª©", "ì¢…ë³„ê°€ì‚°", "ë‹¨ê°€", "ì¢…ë³„ê°€ì‚°ë‹¨ê°€",
    "1íšŒíˆ¬", "Tms/Tot Q", "ì¼ìˆ˜", "ê¸ˆì•¡", "ê¸‰ë¹„", "ê¸‰ë¹„ì§€ì •", "í¬ê´„", "ì™„í™”", "ì›ì™¸", "ë¬´ë£Œ", "ì²˜ë°©ì¼ì", "í•­ëª©ëª…"
]

SECTION_ROW_PATTERN = re.compile(r"^\s*\[\s*.+?\s*\]\s*$")  # [ ì§„ì°°ë£Œ ] ê°™ì€ í–‰


def _clean_lines(raw: str) -> str:
    lines: List[str] = []
    for ln in raw.replace("\r\n", "\n").replace("\r", "\n").splitlines():
        if not ln.strip():
            continue
        if SECTION_ROW_PATTERN.match(ln.strip()):
            continue
        lines.append(ln.lstrip("\t"))
    return "\n".join(lines)


def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).replace("\ufeff", "").strip() for c in df.columns]
    rename_map = {
        "ì²˜ë°© ì½”ë“œ": "ì²˜ë°©ì½”ë“œ",
        "ì²­êµ¬ ì½”ë“œ": "ì²­êµ¬ì½”ë“œ",
        "ì²˜ë°©ì½”ë“œ ": "ì²˜ë°©ì½”ë“œ",
        "ì²­êµ¬ì½”ë“œ ": "ì²­êµ¬ì½”ë“œ",
        "ì²˜ ë°© ì½” ë“œ": "ì²˜ë°©ì½”ë“œ",
        "ì²­ êµ¬ ì½” ë“œ": "ì²­êµ¬ì½”ë“œ",
        "ì²˜ë°©ì½”ë“œ(ë‚´ë¶€)": "ì²˜ë°©ì½”ë“œ",
        "ì²­êµ¬ì½”ë“œ(EDI)": "ì²­êµ¬ì½”ë“œ",
    }
    return df.rename(columns=rename_map)


def parse_clipboard_tsv(raw: str) -> pd.DataFrame:
    cleaned = _clean_lines(raw)
    if not cleaned.strip():
        return pd.DataFrame(columns=EXPECTED_COLS)

    df = pd.read_csv(
        io.StringIO(cleaned),
        sep="\t",
        dtype=str,
        engine="python",
        keep_default_na=False,
    )
    df = _normalize_columns(df)

    # í—¤ë” ì—†ì„ ë•Œ ì¬ì‹œë„
    if ("ì²˜ë°©ì½”ë“œ" not in df.columns) and ("ì²­êµ¬ì½”ë“œ" not in df.columns):
        df2 = pd.read_csv(
            io.StringIO(cleaned),
            sep="\t",
            header=None,
            dtype=str,
            engine="python",
            keep_default_na=False,
        )
        df2 = df2.iloc[:, : len(EXPECTED_COLS)]
        df2.columns = EXPECTED_COLS[: df2.shape[1]]
        df = df2
    else:
        for c in EXPECTED_COLS:
            if c not in df.columns:
                df[c] = ""
        df = df[EXPECTED_COLS].copy()

    # ë‚ ì§œ
    df["ì²˜ë°©ì¼ì"] = df["ì²˜ë°©ì¼ì"].astype(str).str.strip()
    df["ì²˜ë°©ì¼ì_dt"] = pd.to_datetime(df["ì²˜ë°©ì¼ì"], format="%Y%m%d", errors="coerce")

    # ì„¹ì…˜í–‰ ì œê±°
    mask_section = df["ì²˜ë°©ì½”ë“œ"].astype(str).str.strip().str.match(r"^\[.+\]$")
    df = df.loc[~mask_section].copy()

    # ì½”ë“œ ë‘˜ ë‹¤ ë¹„ì–´ìˆëŠ” í•©ê³„í–‰ ì œê±°
    mask_no_codes = (df["ì²˜ë°©ì½”ë“œ"].astype(str).str.strip() == "") & (df["ì²­êµ¬ì½”ë“œ"].astype(str).str.strip() == "")
    df = df.loc[~mask_no_codes].copy()

    # ê¸°ë³¸ trim
    for c in ["í•­ëª©", "ì²˜ë°©ì½”ë“œ", "ì²­êµ¬ì½”ë“œ", "ì²˜ë°©ëª…", "ê¸‰ë¹„", "ì²˜ë°©ì¼ì"]:
        if c in df.columns:
            df[c] = df[c].astype(str).str.replace("\ufeff", "", regex=False).str.strip()

    return df


# -----------------------------
# ì ê²€ ë¡œì§
# -----------------------------
def applied_base_codes_by_date(df_case: pd.DataFrame) -> Dict[str, Set[str]]:
    """
    ë‚ ì§œë³„ ì ìš© ê¸°ì¤€ì½”ë“œ ëª©ë¡
    - ê¸°ì¤€ì½”ë“œ íŒì •: í•­ëª©=0801 í–‰ì—ì„œ RULES[base_code]['base_col'] ê°’ì— base_codeê°€ ë“±ì¥í•˜ë©´ ì ìš©
    """
    out: Dict[str, Set[str]] = {}
    if df_case is None or df_case.empty:
        return out

    d = df_case.copy()
    if "ì²˜ë°©ì¼ì" not in d.columns:
        d["ì²˜ë°©ì¼ì"] = ""
    if "í•­ëª©" not in d.columns:
        d["í•­ëª©"] = ""
    d["ì²˜ë°©ì¼ì"] = d["ì²˜ë°©ì¼ì"].astype(str).str.strip()
    d["í•­ëª©"] = d["í•­ëª©"].astype(str).str.strip()

    for rx_date, g in d.groupby("ì²˜ë°©ì¼ì", dropna=False):
        codes_for_date: Set[str] = set()
        for base_code, rule in RULES.items():
            base_col = rule.get("base_col", "ì²­êµ¬ì½”ë“œ")
            if base_col not in g.columns:
                continue
            base_vals = set(g.loc[g["í•­ëª©"] == "0801", base_col].astype(str).str.strip().tolist())
            base_vals.discard("")
            if base_code in base_vals:
                codes_for_date.add(base_code)
        if codes_for_date:
            out[str(rx_date)] = codes_for_date

    return out


def build_check_table(
    df_case: pd.DataFrame,
    rx_date: str,
    base_code: str,
    item: str,
    check_col: str,
    show_only_missing: bool,
) -> pd.DataFrame:
    """
    item: "0401" or "0801"
    check_col: "ì²­êµ¬ì½”ë“œ" or "ì²˜ë°©ì½”ë“œ" (ì²˜ë°© ë‚´ ì¡´ì¬ ì—¬ë¶€ íŒë‹¨)
    """
    rule = RULES.get(base_code, {})
    rules_list = rule.get("rules_0401", []) if item == "0401" else rule.get("rules_0801", [])
    if not rules_list:
        return pd.DataFrame(columns=["âœ“", "ì½”ë“œ", "ì²­êµ¬ì½”ë“œ", "ì²˜ë°©ì½”ë“œ", "ì½”ë“œëª…", "ë‹¨ê°€", "ê¸‰ë¹„", "case_n"])

    g = df_case.copy()
    g["ì²˜ë°©ì¼ì"] = g.get("ì²˜ë°©ì¼ì", "").astype(str).str.strip()
    g["í•­ëª©"] = g.get("í•­ëª©", "").astype(str).str.strip()
    g[check_col] = g.get(check_col, "").astype(str).str.strip()

    dg = g[g["ì²˜ë°©ì¼ì"] == str(rx_date)].copy()

    obs = set(dg.loc[dg["í•­ëª©"] == item, check_col].astype(str).str.strip().tolist())
    obs.discard("")

    rows: List[dict] = []
    for r in rules_list:
        code = str(r.get("ì½”ë“œ", "")).strip()
        is_present = (code in obs) if code else False
        rows.append(
            {
                "âœ“": is_present,
                "ì½”ë“œ": code,
                "ì²­êµ¬ì½”ë“œ": str(r.get("ì²­êµ¬ì½”ë“œ", "")).strip(),
                "ì²˜ë°©ì½”ë“œ": str(r.get("ì²˜ë°©ì½”ë“œ", "")).strip(),
                "ì½”ë“œëª…": str(r.get("ì½”ë“œëª…", "")).strip(),
                "ë‹¨ê°€": str(r.get("ë‹¨ê°€", "")).strip(),
                "ê¸‰ë¹„": str(r.get("ê¸‰ë¹„", "")).strip(),
                "case_n": int(r.get("case_n", 0) or 0),
            }
        )

    out = pd.DataFrame(rows)
    if show_only_missing:
        out = out[out["âœ“"] == False].copy()

    out = out.sort_values(["âœ“", "case_n", "ì½”ë“œ"], ascending=[True, False, True]).reset_index(drop=True)
    return out


def summarize_result(check_0401: pd.DataFrame, check_0801: pd.DataFrame) -> dict:
    def _cnt(df: pd.DataFrame):
        if df is None or df.empty:
            return (0, 0)
        total = int(len(df))
        ok = int(df["âœ“"].sum()) if "âœ“" in df.columns else 0
        miss = total - ok
        return total, miss

    t40, m40 = _cnt(check_0401)
    t80, m80 = _cnt(check_0801)
    return {
        "0401_total": t40,
        "0401_missing": m40,
        "0801_total": t80,
        "0801_missing": m80,
        "total_missing": m40 + m80,
    }


# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="ê·œì¹™ ëˆ„ë½ ì ê²€(í•˜ë“œì½”ë”©)", layout="wide")
st.title("ê·œì¹™ê²°ê³¼ í•˜ë“œì½”ë”© â†’ ì²˜ë°© ë³µë¶™ë§Œìœ¼ë¡œ 0401/0801 ì ê²€ (ê° íŒŒì¼ case_n ìµœëŒ€ê°’ ê·œì¹™ë§Œ)")

with st.sidebar:
    st.subheader("ì ê²€ ì˜µì…˜")
    check_col = st.radio("ì²˜ë°©ì—ì„œ â€˜ìˆë‹¤/ì—†ë‹¤â€™ íŒë‹¨ ì»¬ëŸ¼", ["ì²­êµ¬ì½”ë“œ", "ì²˜ë°©ì½”ë“œ"], index=0)
    show_only_missing = st.toggle("ëˆ„ë½ë§Œ ë³´ê¸°", value=False)
    st.divider()
    st.caption("â€» ê¸°ì¤€ì½”ë“œëŠ” 'í•­ëª©=0801'ì—ì„œ base_colì— ë“±ì¥í•´ì•¼ ì ìš©ë©ë‹ˆë‹¤.")
    st.caption("â€» RULESëŠ” 'ê° íŒŒì¼ì˜ case_n ìµœëŒ€ê°’'ê³¼ ë™ì¼í•œ í–‰ë§Œ í¬í•¨í•©ë‹ˆë‹¤.")

st.subheader("ì²˜ë°© ë³µë¶™")
if "rx_raw" not in st.session_state:
    st.session_state["rx_raw"] = ""

cbtn, _ = st.columns([1, 5])
with cbtn:
    if st.button("ğŸ§¹ ì…ë ¥ì°½ ë¹„ìš°ê¸°", use_container_width=True):
        st.session_state["rx_raw"] = ""
        st.rerun()

raw = st.text_area("í‘œ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ê¸°(íƒ­ êµ¬ë¶„)", height=220, key="rx_raw")

if not raw.strip():
    st.info("ì²˜ë°©ì„ ë³µë¶™í•˜ë©´ ìë™ìœ¼ë¡œ ê¸°ì¤€ì½”ë“œë¥¼ íŒì •í•˜ê³  ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    st.stop()

df_case = parse_clipboard_tsv(raw)

# ë‚ ì§œë³„ ì ìš© ê¸°ì¤€ì½”ë“œ íŒì •
applied_by_date = applied_base_codes_by_date(df_case)
applied_codes_all = sorted({c for s in applied_by_date.values() for c in s})

# âœ… ê¸°ì¤€ì½”ë“œ ëª©ë¡(ì´ë²ˆ ë³µë¶™ ì ìš© ì—¬ë¶€ ìƒ‰í‘œì‹œ)
with st.expander("ê¸°ì¤€ì½”ë“œ ëª©ë¡ (ì´ë²ˆ ë³µë¶™ì—ì„œ ì ìš©ëœ ê¸°ì¤€ì½”ë“œ ìƒ‰í‘œì‹œ)", expanded=True):
    rows = []
    for base_code, rule in sorted(RULES.items(), key=lambda x: x[0]):
        rows.append(
            {
                "ê¸°ì¤€ì½”ë“œ": base_code,
                "base_col": rule.get("base_col", ""),
                "case_n_max": rule.get("case_n_max", ""),
                "0401ê·œì¹™ìˆ˜": len(rule.get("rules_0401", [])),
                "0801ê·œì¹™ìˆ˜": len(rule.get("rules_0801", [])),
                "ì´ë²ˆë³µë¶™_ì ìš©ì—¬ë¶€": (base_code in applied_codes_all),
            }
        )
    df_list = (
        pd.DataFrame(rows)
        .sort_values(["ì´ë²ˆë³µë¶™_ì ìš©ì—¬ë¶€", "ê¸°ì¤€ì½”ë“œ"], ascending=[False, True])
        .reset_index(drop=True)
    )

    def _hl(row):
        return ["background-color:#d1fae5"] * len(row) if bool(row.get("ì´ë²ˆë³µë¶™_ì ìš©ì—¬ë¶€")) else [""] * len(row)

    st.dataframe(df_list.style.apply(_hl, axis=1), use_container_width=True)
    st.caption("ì´ë²ˆ ë³µë¶™ì—ì„œ ì ìš©ëœ ê¸°ì¤€ì½”ë“œ: " + (", ".join(applied_codes_all) if applied_codes_all else "(ì—†ìŒ)"))

if not applied_by_date:
    st.warning("ì´ë²ˆ ë³µë¶™ì—ì„œëŠ” ì–´ë–¤ ê¸°ì¤€ì½”ë“œë„(í•­ëª©=0801 ê¸°ì¤€) ë°œê²¬ë˜ì§€ ì•Šì•„ ê·œì¹™ì„ ì ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

st.divider()
st.subheader("ì ê²€ ê²°ê³¼ (ë‚ ì§œ Ã— ê¸°ì¤€ì½”ë“œ)")

# ë‚ ì§œë³„ ì„¹ì…˜
for rx_date in sorted(applied_by_date.keys()):
    codes = sorted(applied_by_date[rx_date])
    st.markdown(f"### ì²˜ë°©ì¼ì: {rx_date}  |  ì ìš© ê¸°ì¤€ì½”ë“œ: {', '.join(codes)}")

    for base_code in codes:
        colL, colR = st.columns(2)

        # í‘œì‹œìš©(ëˆ„ë½ë§Œ ë³´ê¸° ì˜µì…˜ ì ìš©)
        view_0401 = build_check_table(df_case, rx_date, base_code, "0401", check_col, show_only_missing)
        view_0801 = build_check_table(df_case, rx_date, base_code, "0801", check_col, show_only_missing)

        # ìš”ì•½ìš©(í•­ìƒ ì „ì²´ ê¸°ì¤€)
        full_0401 = build_check_table(df_case, rx_date, base_code, "0401", check_col, False)
        full_0801 = build_check_table(df_case, rx_date, base_code, "0801", check_col, False)
        summary = summarize_result(full_0401, full_0801)

        # âœ… ê²°ë¡ (ìš”ì•½)
        if summary["total_missing"] == 0:
            st.success(f"âœ… ê¸°ì¤€ì½”ë“œ {base_code}: ëˆ„ë½ ì—†ìŒ (0401 {summary['0401_total']}ê°œ / 0801 {summary['0801_total']}ê°œ)")
        else:
            st.error(
                f"âš ï¸ ê¸°ì¤€ì½”ë“œ {base_code}: ëˆ„ë½ {summary['total_missing']}ê°œ "
                f"(0401 ëˆ„ë½ {summary['0401_missing']}/{summary['0401_total']}, "
                f"0801 ëˆ„ë½ {summary['0801_missing']}/{summary['0801_total']})"
            )

        with colL:
            st.markdown(f"**0401 ì²´í¬ë¦¬ìŠ¤íŠ¸ â€” ê¸°ì¤€ì½”ë“œ {base_code}**")
            st.dataframe(
                view_0401,
                use_container_width=True,
                column_config={
                    "âœ“": st.column_config.CheckboxColumn("âœ“", help="í˜„ì¬ ì²˜ë°©(í•´ë‹¹ ë‚ ì§œ)ì— ì¡´ì¬í•˜ë©´ ì²´í¬"),
                    "case_n": st.column_config.NumberColumn("case_n"),
                },
            )

        with colR:
            st.markdown(f"**0801 ì²´í¬ë¦¬ìŠ¤íŠ¸ â€” ê¸°ì¤€ì½”ë“œ {base_code}**")
            st.dataframe(
                view_0801,
                use_container_width=True,
                column_config={
                    "âœ“": st.column_config.CheckboxColumn("âœ“", help="í˜„ì¬ ì²˜ë°©(í•´ë‹¹ ë‚ ì§œ)ì— ì¡´ì¬í•˜ë©´ ì²´í¬"),
                    "case_n": st.column_config.NumberColumn("case_n"),
                },
            )

    st.divider()

# -----------------------------
# ë‹¤ìš´ë¡œë“œ (openpyxl ì—†ìœ¼ë©´ CSVë¡œ ìë™ ëŒ€ì²´)
# -----------------------------
st.subheader("ë‹¤ìš´ë¡œë“œ")

out_rows = []
for rx_date, codes in applied_by_date.items():
    for base_code in codes:
        for item in ["0401", "0801"]:
            tbl = build_check_table(df_case, rx_date, base_code, item, check_col, False)
            if tbl.empty:
                continue
            tbl2 = tbl.copy()
            tbl2.insert(0, "í•­ëª©", item)
            tbl2.insert(0, "ê¸°ì¤€ì½”ë“œ", base_code)
            tbl2.insert(0, "ì²˜ë°©ì¼ì", rx_date)
            out_rows.append(tbl2)

if not out_rows:
    st.info("ë‹¤ìš´ë¡œë“œí•  ì²´í¬ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

out_df = pd.concat(out_rows, ignore_index=True)

# 1) xlsx ì‹œë„
can_xlsx = True
try:
    import openpyxl  # noqa: F401
except Exception:
    can_xlsx = False

if can_xlsx:
    x = io.BytesIO()
    with pd.ExcelWriter(x, engine="openpyxl") as writer:
        out_df.to_excel(writer, index=False, sheet_name="checklist")

    st.download_button(
        "ğŸ“¥ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ(Excel .xlsx)",
        data=x.getvalue(),
        file_name=f"ì²´í¬ë¦¬ìŠ¤íŠ¸_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True,
    )
else:
    csv_bytes = out_df.to_csv(index=False).encode("utf-8-sig")
    st.warning("âš ï¸ openpyxlì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ XLSX ëŒ€ì‹  CSVë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. (requirementsì— openpyxl ì¶”ê°€í•˜ì„¸ìš”)")
    st.download_button(
        "ğŸ“¥ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ(CSV)",
        data=csv_bytes,
        file_name=f"ì²´í¬ë¦¬ìŠ¤íŠ¸_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
        use_container_width=True,
    )
